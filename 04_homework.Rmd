---
title: "SMDS Homework - Block 4"
author: "P. Morichetti, M. Rispoli, A. Cicchini and E. Ballarin  |  Group 'B'"
date: "27th May 2020"
output:
  html_document:
    theme: darkly
    highlight: breezedark
    mathjax: default
    self_contained: true
    md_extensions: +autolink_bare_uris
    toc: true
    toc_collapsed: false
    toc_float: true
    toc_depth: 3
    number_sections: false
header-includes:
- \usepackage{color}
- \usepackage{graphicx}
- \usepackage{grffile}
institute: University of Trieste, SISSA, ICTP, University of Udine
graphics: yes
fontsize: 10pt
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.align = 'center', warning=FALSE, message=FALSE, fig.asp=0.625, dev='png', global.par = TRUE, dev.args=list(pointsize=10), fig.path = 'figs/')
```

```{r setup, include=FALSE}
library(knitr)
local({
  hook_plot = knit_hooks$get('plot')
  knit_hooks$set(plot = function(x, options) {
    paste0('\n\n----\n\n', hook_plot(x, options))
  })
})
```


# Exercises from *DAAG, Chapter 6* 

## Exercise 6

### Text

### Solution

<!-- # Some code... -->
```{r daag_06_06, code = readLines("src/DAAG_06_06.R"), echo=TRUE}
```

### Comments

After having fit both *Model 1* (i.e. the linear model that tries to explain record `time` for male athletes from the `dist`ance and `climb` variables, without considering the interaction term) and *Model 1* (the one considering also interaction between `dist` and `climb`) on the entire, untransformed, `nihills` dataset, we can look at *Fisher-test ANOVA* for model selection, being *Model 1* nested inside *Model 2*.  

With a value of $F = 72.406$ and a *p-value* $<10^{-7}$ *Model 2* is evidently (according to the *F-test*) the model of choice in such setting.  

Upon inspection, however, it appears clear that the relatively poor behaviour of *Model 1* as opposed to *Model 2* is strongly determined by the influence of few data-points.  

In fact, considering for the moment *Model 1*:

- From the *Residuals vs Fitted* graph, it appears clearly that tracks *Seven Sevens* and *Annalong Horseshoe* have both highest residuals (though of opposite sign) and highest fitted values. This evidence of heteroscedasticity is further confirmed by the *Scale-Location* plot.  
- From the *Residuals vs Leverage* plot we know that the *Seven Sevens* track is also a potential influential point.

Now, looking at *Model 2*, we can see that:
- The *Seven Sevens* track has become one of the datapoints with the smallest residuals.  
- Such datapoint still exhibits high leverage and is a candidate to be an influential point.  

We can therefore conclude that the additional interaction term mainly serves the purpose of correcting the model for taking into account the appearantly *strange* behaviour of *Seven Sevens* in *Model 1*.  

We try to re-fit the model on the (still, untransformed) `nihills` dataset, after removal of the *Seven Sevens* datapoint.  

This time, *Fisher-test ANOVA* suggests to avoid the additional interaction term, proving our assumption as probably correct.  

Now, at the price of some additional non-normality even at central quantiles, and without solving the still present problem of heteroscedasticity, the model is less determined by influence of single-datapoints.  

Still, what previously observed for the *Seven Sevens* track can now be found -- even if with a smaller effect overall -- w.r.t. the *Annalong Horseshoe*.  

Repeating the fit with the dataset additionally devoid of the *Annalong Horseshoe* datapoint, here-evidenced conclusions are even more amplified: *Annalong Horseshoe* was an influential point even in the latter case.  

The interesting point to be noted with such regard is that -- being the *Seven Sevens* and *Annalong Horseshoe* datapoints those whose outlying *time* value is the farthest from the linear trends *time/dist* and *time/climb* -- the lack of proper logarithmic transform of the dataset both produces inaccurate models and also tricks the analyst into preferring an over-parametrized model whose effest is just to amplify the importance of outlying value(s).

## Exercise 8

### Text

Apply the `lm.ridge()` function to the `litters` data, using the generalized cross-validation (GCV) criterion to choose the tuning parameter. (GCV is an approximation to cross-validation.)

a. In particular, estimate the coefficients of the model relating `brainwt` to `bodywt` and `lsize` and compare with the results obtained using `lm()`.  
b. Using both ridge and ordinary regression, estimate the mean brain weight when litter size is 10 and body weight is 7. Use the bootstrap, with case-resampling, to compute approximate 95% percentile confidence intervals using each method. Compare with the interval obtained using `predict.lm()`.

### Solution

Let's begin by taking a quick look at the data

```{r daag6_8a, echo=TRUE}
library(DAAG)
library(MASS) #for lm.ridge()

head(litters)
plot(litters)
```

From the basic plot we can immediately tell that  
- `brainwt` is positively correlated to `bodywt` and negatively correlated to `lsize`, although the correlation appears to be very noisy;  
- There's a significative negative correlation between `bodywt` and `lsize`;


we may expect some problems arising from the collinearity underlined in the second bullet when fitting `brainwt` w.r.t. `bodywt` and `lsize`.

Let's see how the linear model and ridge regression do:

```{r daag6_8b,echo=TRUE}

# fit the vanilla linear model
litters.lm = lm(brainwt~bodywt+lsize, data=litters)
summary(litters.lm)

# fit the ridge linear regression (selecting lambda by GCV)
select(lm.ridge(brainwt~bodywt+lsize, data=litters,
                lambda = seq(0,1,0.001)))
best.lambda = .118
litters.ridge = lm.ridge(brainwt~bodywt+lsize, data=litters,
                         lambda=best.lambda)
litters.ridge


# estimate train MSE for comparing the models

# function that computes the predictions of a lm.ridge() model
predridge <- function(model = litters.ridge, littersdf = litters){
  coeffs = coef(model)
  return(coeffs[1] + coeffs[2] * littersdf$bodywt + coeffs[3] * littersdf$lsize)
}

litters.ridge.residuals <- litters$brainwt - predridge()

print(paste("lm MSE: ",
            sum(litters.lm$residuals**2) / length(litters.lm$residuals)))
print(paste("ridge MSE: ",
            sum(litters.ridge.residuals**2) / length(litters.ridge.residuals)))

```
The coefficients estimated in ridge regression for both predictors are slightly smaller than those fitted by the linear model without regolarization, which is something that we expect to see in ridge regression, although the intercept's value increases slightly. 

We can compare the model looking at the train MSE, which actually shows a very small difference in favour of the model without regolarization.

Let's now check our models' prediction on a the novel sample $(7,10)$. We'll also estimate the percentile bootstrap 95% confidence interval for both methods for the sample and compare them with the 95% CI reported by `lm()`:

```{r daag6_8c, echo=TRUE}

# estimate models on the new datapoint
newpoint = data.frame(bodywt=7, lsize=10)

yhat.lm <- predict(litters.lm, newdata = newpoint)
yhat.ridge <- predridge(litters.ridge,newpoint)

# estimate percentile bootstrap CI for lm and lm.ridge at newpoint

n <- nrow(litters)
B = 1000

lm.bs = 1:B
ridge.bs = 1:B

for(b in 1:B){
  idxs = sample (1:n,n, replace = TRUE)
  bootdf = litters[idxs,]
  
  b_lm = lm(brainwt~ bodywt + lsize, data = bootdf)
  lm.bs[b] <- predict(b_lm, newdata = newpoint)
  
  b_ridge = lm.ridge(brainwt~ bodywt + lsize, data = bootdf, lambda = best.lambda)
  ridge.bs[b] <- predridge(b_ridge, newpoint)
}


lm.ci = quantile(lm.bs,probs=c(0.025,0.975))

ridge.ci = quantile(ridge.bs,probs=c(0.025,0.975))

print("lm estimate + bootstrap 95% CI:")
print(paste(yhat.lm, "(", lm.ci[1],",",lm.ci[2],")"))

print("ridge estimate + bootstrap 95% CI:")
print(paste(yhat.ridge, "(", ridge.ci[1],",",ridge.ci[2],")"))

print("lm() estimate and CI")
predict(litters.lm, newdata = newpoint,interval="confidence", level=.95)

lm.cibase = predict(litters.lm, newdata = newpoint,interval="confidence", level=.95)[2:3]

#plot the three intervals 
plot(as.factor(c("lm+bs","lm+wald","ridge+bs")),c(yhat.lm,yhat.lm,yhat.ridge),       
     ylim=c(.404,.425))

lines(c(1,1),lm.ci, col="red")
lines(c(2,2),lm.cibase, col="red")
lines(c(3,3),ridge.ci, col="red")

```

We can see from the graph that the bootstrap CI slightly asymmetric, but once again the difference in the estimates is very small.

## Exercise 10

### Text

### Solution
```{r daag06_10, code = readLines("src/DAAG_06_10.R"), echo=TRUE}
```

### Comments
<!-- TODO: Michele Rispoli -->
Something...

## Exercise 11

### Text

### Solution

# Exercises from *DAAG, Chapter 8* 

## Exercise 1

### Text

### Solution

## Exercise 2

### Text

### Solution


## Exercise 3

### Text

### Solution


## Exercise 6

### Text

### Solution
```{r daag08_06, code = readLines("src/DAAG_08_06.R"), echo=TRUE}
```

### Comments
<!-- TODO -->
Text to be written. Please leave it here!

<!-- LEAVE A NEWLINE AT THE END-OF-FILE! -->
